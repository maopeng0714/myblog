+++
title = "高可用K8S集群部署"
date = "2019-10-15"
author = "Peng Mao"
description = "详细讲解怎么在自己的电脑上搭建起利用HAPROXY+KEEPALIVED的高可用K8S集群"
+++


#### 安装配置虚拟机

- 下载Virtual Box 和 CentOS 镜像。
- 下载CentOS 7任意镜像版本，注意不要下载CentOS 8，有兼容性问题。
- 软件包选择Infrustructure Server, 虽然不带图形界面节省空间但是也带有必要的组件。
- 配置yum源

    ``` bash
    wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
    yum makecache
    yum update
    ```

- 关闭、禁用防火墙：

    ```bash
    systemctl stop firewalld
    systemctl disable firewalld
    ```

- 禁用SELINUX：
  只有执行这一操作之后，容器才能访问宿主的文件系统，进而能够正常使用 Pod 网络。您必须这么做，直到 kubelet 做出升级支持 SELinux 为止

   ```bash
   setenforce 0
   ```

- 关闭Swap

  ```bash
   - swapoff -a可临时关闭，但系统重启后恢复
   - 编辑/etc/fstab，注释掉包含swap的那一行即可，重启后可永久关闭，如下所示：
  ```

- 设置主机名

    ```bash
    - hostname kube-master 临时改变
    - 编辑/etc/hosts 文件
    - 编辑 /etc/sysconfig/network 加入hostname
    ```

#### 设置虚拟机网络

一般情况下，虚拟机的网络模式有两种选择，NAT或者上Bridge，在NAT模式下，虚拟机从属于主机，也就是访问外部网络必须通过主机来访问，因此虚拟机的IP只有主机才能识别。而Bridge桥接模式下，虚拟机和主机是平行关系，共享一张网卡（使用网卡的多个接口），可以直接访问外部网络。
因此如果要想从主机上直接访问虚拟机的服务，需要用桥接模式而非NAT模式。但是桥接模式的IP一般会变动，为了避免每次远程连接都要重新设置IP，这里设置成静态IP。

- 在VirtualBox中网络设置添加2块网卡，第一块网卡设置为hostonly网络用于集群内部沟通，第二块网卡设置为NAT模式用于通过主机上网。

- 编辑 /etc/sysconfig/network文件（主机名、默认网关、DNS）

    ```bash
      # Created by anaconda
        NETWORKING=yes
        DNS1=8.8.8.8
        DNS2=8.8.4.4
        HOSTNAME=kube-master
    ```

- 设置用于内部通讯的第一块网卡的固定IP
  编辑 /etc/sysconfig/network-scripts/ifcfg-enp0s3（配置ip地址、网关、DNS）

    ```bash
        TYPE="Ethernet"
        PROXY_METHOD=none
        BROWSER_ONLY=no
        NM_CONTROLLED=no
        BOOTPROTO="static"
        DEFROUTE="yes"
        IPV4_FAILURE_FATAL="no"
        NAME="enp0s3"
        DEVICE="enp0s3"
        ONBOOT="yes"
        IPADDR="192.168.56.10"
        NETMASK="255.255.255.0"
    ```

- 编辑 /etc/resolve.conf文件(配置DNS解析)

    ```bash
        # Generated by NetworkManager
        nameserver 8.8.8.8
        nameserver 8.8.4.4
    ```

- 重启网络服务

``` bash
     systemctl restart network
```

#### 安装Docker

 注意安装k8s支持的版本，不要太高

- 安装必要的一些系统工具

```bash
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
```

- 添加软件源信息

```bash
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```

- 更新并安装 Docker-CE

```bash
sudo yum makecache fast
yum list docker-ce.x86_64  --showduplicates |sort -r
yum install -y --setopt=obsoletes=0 docker-ce-18.09.8-3.el7
```

- 开启Docker服务

```bash
# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF
sudo service docker start
```

- 设置开机启动

```bash
sudo systemctl enable docker
```

如果报错说docker版本太高，卸载docker，选择合适的版本重装：

``` bash
yum -y remove docker-ce.x86_64
yum -y remove docker-ce-cli.x86_64
yum -y remove containerd.io.x86_64
rm -rf /var/lib/docker
yum list docker-ce.x86_64  --showduplicates |sort -r
yum install -y --setopt=obsoletes=0 docker-ce-18.09.8-3.el7
systemctl start docker
systemctl enable docker
```

#### 网桥配置

配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要

```bash
echo """
vm.swappiness = 0
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
""" > /etc/sysctl.conf
sysctl -p
```

#### 配置内核参数

```bash
# https://github.com/moby/moby/issues/31208 
# ipvsadm -l --timout
# 修复ipvs模式下长连接timeout问题 小于900即可
cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 10
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv4.neigh.default.gc_stale_time = 120
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
net.ipv4.conf.all.arp_announce = 2
net.ipv4.ip_forward = 1
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 1024
net.ipv4.tcp_synack_retries = 2
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.netfilter.nf_conntrack_max = 2310720
fs.inotify.max_user_watches=89100
fs.may_detach_mounts = 1
fs.file-max = 52706963
fs.nr_open = 52706963
net.bridge.bridge-nf-call-arptables = 1
vm.swappiness = 0
vm.overcommit_memory=1
vm.panic_on_oom=0
EOF
sysctl --system

```

#### 开启并加载IPVS模块

在所有的Kubernetes节点执行以下脚本（若内核大于4.19替换nf_conntrack_ipv4为nf_conntrack）:

```bash
cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
#执行脚本
chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4
#安装相关管理工具
yum install ipset ipvsadm -y

```

#### 安装kubelet，kubeadm，kubectl

```bash
#配置kubernetes.repo为阿里云
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg  http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum install -y kubeadm-1.14.7-0 kubectl-1.14.7-0  kubelet-1.14.7-0  --setopt=obsoletes=0 --disableexcludes=kubernetes
systemctl enable --now kubelet.service
```

#### 配置kubelet

确保docker 的cgroup driver 和kubelet的cgroup driver一样：

```bash
docker info | grep -i cgroup

vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf

vim /var/lib/kubelet/config.yaml

vim /var/lib/kubelet/kubeadm-flags.env
KUBELET_KUBEADM_ARGS="--cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1"

更新为 cgroupDriver: systemd

vim /etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS= --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice

systemctl daemon-reload
systemctl restart kubelet
```

#### 复制虚拟机

将Master虚拟机复制两份，一个修改hostname 为kube-node1, 另一个为kube-node2.
修改上面指定的的固定IP地址，防止冲突。

### 高可用集群部署方案之HAPROXY+Keepalived

本次部署一个两节点高可用 haproxy+keepalived 集群，和Master节点部署在一起，分别为：192.168.56.10、192.168.56.11。计划使用VIP 地址 192.168.56.33

#### 安装 haproxy+keepalived

yum install -y haproxy keepalived

注： 2台master的 haproxy+keepalived 节点都需安装

#### 配置 keepalived

节点1:192.168.56.10

VIP 所在的接口（interface ${VIP_IF}）为 enp0s3；
使用 killall -0 haproxy 命令检查所在节点的 haproxy 进程是否正常。如果异常则将权重减少（-30）,从而触发重新选主过程；
router_id、virtual_router_id 用于标识属于该 HA 的 keepalived 实例，如果有多套 keepalived HA，则必须各不相同；
priority 的值必须小于 master 的值；

```bash

vim /etc/keepalived/keepalived.conf

! Configuration File for keepalived

global_defs {
   router_id LVS_DEVEL
   vrrp_skip_check_adv_addr
}

vrrp_instance VI_1 {
    state MASTER
    interface enp0s3
    virtual_router_id 51
    priority 100
    advert_int 1
    virtual_ipaddress {
        192.168.56.33
    }
}

```

keepalived配置文件基本一样，除了state，主节点配置为MASTER，备节点配置BACKUP，优化级参数priority，主节点设置最高，备节点依次递减

#### 配置 haproxy

2台节点的配置一样

```bash
vim /etc/haproxy/haproxy.cfg
添加如下段落：
global
  log 127.0.0.1 local0 err
  maxconn 4096
  uid 99
  gid 99
  #daemon
  nbproc 1
  pidfile haproxy.pid

defaults
  mode http
  log 127.0.0.1 local0 err
  maxconn 4096
  retries 3
  timeout connect 5s
  timeout client 30s
  timeout server 30s
  timeout check 2s

listen admin_stats
  mode http
  bind 0.0.0.0:1080
  log 127.0.0.1 local0 err
  stats refresh 30s
  stats uri     /haproxy-status
  stats realm   Haproxy\ Statistics
  stats auth    admin:admin
  stats hide-version
  stats admin if TRUE

frontend k8s-https
  bind 0.0.0.0:8443
  mode tcp
  #maxconn 4096
  default_backend k8s-https

backend k8s-https
  mode tcp
  balance roundrobin
  server kube-master  192.168.56.10:6443 weight 1 maxconn 1000 check inter 2000 rise 2 fall 3
  server kube-master2 192.168.56.11:6443 weight 1 maxconn 1000 check inter 2000 rise 2 fall 3

```

haproxy 在 1080 端口输出 status 信息；
haproxy 监听所有接口的 8443 端口，该端口与环境变量 ${KUBE_APISERVER} 指定的端口必须一致；
server 字段列出所有 kube-apiserver 监听的 IP 和端口；

#### 启动 haproxy+keepalived

2个节点都启动

systemctl daemon-reload
systemctl enable haproxy
systemctl enable keepalived
systemctl start haproxy
systemctl start keepalived

#### K8S 主节点安装配置

导出默认配置并修改为需要的配置如下：
kubeadm config print init-defaults > kubeadm-config.yaml

```bash
apiVersion: kubeadm.k8s.io/v1beta1
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.56.10
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: kube-master
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta1
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: "192.168.56.33:8443"
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.14.7
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
  podSubnet: 192.168.0.0/16
scheduler: {}
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs

```

#### 初始化高可用集群

初始化第一个主节点：

kubeadm init --config=kubeadm-config.yaml --experimental-upload-certs

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

cat << EOF >> ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source ~/.bashrc

初始化其他主节点：

kubeadm join 192.168.56.33:8443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:e8f36e9f3092aad715913b0eaa6196ece15c57a98db740759332eabde220a03b \
    --experimental-control-plane --certificate-key 120e900b1611e82fd43b1bbfb68e8bcabfecbd06f419f06badc2a9cc98a6ab56

初始化工作节点：

kubeadm join 192.168.56.33:8443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:e8f36e9f3092aad715913b0eaa6196ece15c57a98db740759332eabde220a03b

将kubeconfig配置SCP到其他所有节点：
scp /root/.kube/config   root@kube-master2:/root/.kube/config
scp /root/.kube/config   root@kube-node1:/root/.kube/config
scp /root/.kube/config   root@kube-node2:/root/.kube/
